{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982966e2",
   "metadata": {},
   "source": [
    "## MLBookCamp Homework 3\n",
    "\n",
    "- [Course page](https://datatalks.club/courses/2021-winter-ml-zoomcamp.html)\n",
    "\n",
    "- [Homework page](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/03-classification/homework.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4738471",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we will continue the New York City Airbnb Open Data. You can take it from [Kaggle](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv) or download from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv) if you don't want to sign up to Kaggle.  \n",
    "\\\n",
    "We'll keep working with the 'price' variable, and we'll transform it to a classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c147607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic modules beforehand\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c743296",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d955102",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv -O 'airbnb.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('airbnb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816347b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b98fb",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "For the rest of the homework, you'll need to use the features from the previous homework with additional two 'neighbourhood_group' and 'room_type'. So the whole feature set will be set as follows:\n",
    "\n",
    "    'neighbourhood_group',\n",
    "    'room_type',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'price',\n",
    "    'minimum_nights',\n",
    "    'number_of_reviews',\n",
    "    'reviews_per_month',\n",
    "    'calculated_host_listings_count',\n",
    "    'availability_365'\n",
    "\n",
    "Select only them and fill in the missing values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c240b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features to be used\n",
    "features = [\n",
    "'neighbourhood_group',\n",
    "'room_type',\n",
    "'latitude',\n",
    "'longitude',\n",
    "'minimum_nights',\n",
    "'number_of_reviews',\n",
    "'reviews_per_month',\n",
    "'calculated_host_listings_count',\n",
    "'availability_365',\n",
    "'price'\n",
    "]\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91faa4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching desired df\n",
    "abnb_df = df[features]\n",
    "abnb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e477ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnb_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee9851",
   "metadata": {},
   "source": [
    "> Select only them and fill in the missing values with 0.\n",
    "\n",
    "From df info, we can observe there is one column: `reviews_per_month` with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc51977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nan values with 0\n",
    "abnb_df['reviews_per_month'] = abnb_df['reviews_per_month'].fillna(0)\n",
    "\n",
    "abnb_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69fa80",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column 'neighbourhood_group'?\n",
    "> Manhattan : 21661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch mode using value_counts\n",
    "abnb_df['neighbourhood_group'].value_counts(ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414d0c1",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "   -  Split your data in train/val/test sets, with 60%/20%/20% distribution.  \n",
    "    \n",
    "   -  Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.  \n",
    "    \n",
    "   -  Make sure that the target value ('price') is not in your dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice price column \n",
    "target = abnb_df['price'].to_frame()\n",
    "\n",
    "# Drop price column from df\n",
    "abnb_df.drop(columns='price', inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b84133",
   "metadata": {},
   "source": [
    "### Make price binary\n",
    "\n",
    "   -  We need to turn the price variable from numeric into binary.\n",
    "   -  Let's create a variable above_average which is 1 if the price is above (or equal to) 152.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7f7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize price\n",
    "target['above_avg'] = (target['price'] >= 152).astype(int)\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd4c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(abnb_df, target, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "f'Train size: {len(x_train)}, {len(y_train)}\\n'\n",
    "f'Val size: {len(x_val)}, {len(y_val)}\\n'\n",
    "f'Test size: {len(x_test)}, {len(y_test)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4571b8",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "- Create the correlation matrix for the numerical features of your train dataset.\n",
    "    - In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n",
    "- What are the two features that have the biggest correlation in this dataset?  \n",
    "\n",
    "\n",
    "> `reviews_per_month` and `number_of_reviews` -> 0.549792\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate correlation\n",
    "corr = x_train.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a62da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill diagonal and upper half with NaNs\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "corr[mask] = np.nan\n",
    "(corr\n",
    " .style\n",
    " .background_gradient(cmap='coolwarm', axis=None, vmin=-1, vmax=1)\n",
    " .highlight_null(null_color='#f1f1f1')  # Color NaNs grey\n",
    " .set_precision(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e456b98",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "- Calculate the mutual information score with the (binarized) price for the two categorical variables that we have. Use the training set only.\n",
    "- Which of these two variables has bigger score?\n",
    "- Round it to 2 decimal digits using round(score, 2)\n",
    "\n",
    "> Room type has bigger score (0.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425177ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# Fetch numerical columns\n",
    "num_cols = list(x_train.select_dtypes(include=['int64', 'float64']).columns)\n",
    "print(num_cols)\n",
    "\n",
    "# Fetch categorical columns\n",
    "cat_cols = list(x_train.select_dtypes(include=['object']).columns)\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate mutual info score\n",
    "mi_ng = mutual_info_score(x_train['neighbourhood_group'], y_train['above_avg']).round(2)\n",
    "mi_rt = mutual_info_score(x_train['room_type'], y_train['above_avg']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa865225",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "f'Mutual information of neighbourhood group with target: {mi_ng}\\n'\n",
    "f'Mutual information of room type with target: {mi_rt}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad4bb0",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "- Now let's train a logistic regression\n",
    "- Remember that we have two categorical variables in the data. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "    - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)\n",
    "- Calculate the accuracy on the validation dataset and rount it to 2 decimal digits.\n",
    "\n",
    "> Validation accuracy is 0.79\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c740a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Trying OHE for categorical columns\n",
    "# Create instance of OHE\n",
    "ohe = OneHotEncoder(sparse= False)\n",
    "\n",
    "# Fitting categorical columns to encoder instances\n",
    "ohe.fit(x_train[cat_cols])\n",
    "\n",
    "# Fetching encoded column names\n",
    "enc_cols = list(ohe.get_feature_names(cat_cols))\n",
    "print(f'Encoded columns: {enc_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b96dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform/Encode categorical columns\n",
    "x_train[enc_cols] = ohe.transform(x_train[cat_cols])\n",
    "x_val[enc_cols] = ohe.transform(x_val[cat_cols])\n",
    "x_test[enc_cols] = ohe.transform(x_test[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c56a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create instance of logReg model\n",
    "lr = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)\n",
    "lr.fit(x_train[num_cols+enc_cols], y_train['above_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80329d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set and evaluate accuracy\n",
    "y_pred = lr.predict(x_val[num_cols+enc_cols])\n",
    "val_acc = accuracy_score(y_val['above_avg'], y_pred)\n",
    "print(f'Validation accuracy is {round(val_acc, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a05e793",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "- We have 9 features: 7 numerical features and 2 categorical.  \n",
    "\n",
    "- Let's find the least useful one using the feature elimination technique.\n",
    "- Train a model with all these features (using the same parameters as in Q4).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "- Which of following feature has the smallest difference?\n",
    "        neighbourhood_group\n",
    "        room_type\n",
    "        number_of_reviews\n",
    "        reviews_per_month\n",
    "\n",
    "note: the difference doesn't have to be positive\n",
    "\n",
    "\n",
    "> `number_of_reviews`: -0.00072 has lowest difference  \n",
    "Difference of score without column `neighbourhood_group`: 0.03538  \n",
    "Difference of score without column `room_type`: 0.07117  \n",
    "Difference of score without column `number_of_reviews`: -0.00072  \n",
    "Difference of score without column `reviews_per_month`: 0.00123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4310194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance by model coefficients\n",
    "pd.DataFrame(data= {'feature': num_cols+enc_cols, 'coef': abs(lr.coef_[0])}).sort_values(by='coef',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e9c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_acc = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Create list of features to be dropped\n",
    "elim_feat = ['neighbourhood_group', 'room_type', 'number_of_reviews', 'reviews_per_month']\n",
    "\n",
    "dv_train_df = x_train[num_cols+cat_cols].copy()\n",
    "dv_val_df = x_val[num_cols+cat_cols].copy()\n",
    "\n",
    "\n",
    "# For each feature in elim_feat, drop it, train model, evaluate accuracy and compare with original_acc\n",
    "for i in elim_feat:\n",
    "    dv = DictVectorizer(sparse= False)\n",
    "    \n",
    "    train_dict = dv_train_df.drop(columns=i).to_dict(orient= 'records')\n",
    "    dv_train = dv.fit_transform(train_dict)\n",
    "    \n",
    "    val_dict = dv_val_df.drop(columns=i).to_dict(orient= 'records')\n",
    "    dv_val =dv.fit_transform(val_dict)\n",
    "    \n",
    "    lr_dict = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)\n",
    "    lr_dict.fit(dv_train, y_train['above_avg'])\n",
    "    \n",
    "    lr_dict_pred = lr_dict.predict(dv_val)\n",
    "    score = accuracy_score(y_val['above_avg'], lr_dict_pred)\n",
    "    print(f'Difference of score without column {i}: {round(original_acc - score, 5)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dbfe02",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "- For this question, we'll see how to use a linear regression model from Scikit-Learn\n",
    "- We'll need to use the original column `price`. Apply the logarithmic transformation to this column.\n",
    "- Fit the Ridge regression model on the training data.\n",
    "- This model has a parameter alpha. Let's try the following values: [0, 0.01, 0.1, 1, 10]\n",
    "- Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits.\n",
    "\n",
    "If there are multiple options, select the smallest alpha.\n",
    "\n",
    "> alpha = 0.01   \n",
    "    [(0, 0.22), (0.01, 0.218), (0.1, 0.218), (1, 0.218), (10, 0.218)]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a817d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate log and impute any undesired values\n",
    "y_train['price'] = np.log10(y_train['price']).fillna(0).replace([np.inf, -np.inf], 0)\n",
    "y_val['price'] = np.log10(y_val['price']).fillna(0).replace([np.inf, -np.inf], 0)\n",
    "y_test['price'] = np.log10(y_test['price']).fillna(0).replace([np.inf, -np.inf], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b2ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_params(**params):\n",
    "    \"\"\"\n",
    "    - Train a ridge model with hyperparameter passed to function \n",
    "    - Predict  on validation set\n",
    "    - Evaluate MSE\n",
    "    \"\"\"\n",
    "    model = Ridge( **params).fit(x_train[num_cols+enc_cols], y_train['price'])\n",
    "    pred = model.predict(x_val[num_cols+enc_cols])\n",
    "    val_rmse = mean_squared_error(y_val['price'], pred,  squared=False)\n",
    "    return val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1224c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multiple_values(param_name, param_values):\n",
    "    \"\"\"\n",
    "    For given param_name and range of values, train a model individually through function test_params\n",
    "    and fetch-append validation RMSE\n",
    "    \"\"\"\n",
    "    val_errors = []\n",
    "    for value in param_values:\n",
    "        params = {param_name: value}\n",
    "        metric = test_params(**params)\n",
    "        val_errors.append(round(metric, 3))\n",
    "    return val_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6885d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile param values and rmse values together\n",
    "list(zip([0, 0.01, 0.1, 1, 10],(test_multiple_values('alpha', [0, 0.01, 0.1, 1, 10]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b022d13",
   "metadata": {},
   "source": [
    "### References\n",
    "- [sklearn](https://scikit-learn.org/stable/index.html)\n",
    "- [pandas](https://pandas.pydata.org/docs/user_guide/index.html#user-guide)\n",
    "- [mlbookcamp chapter 3](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/03-classification/README.md)\n",
    "- [test_params function template](https://jovian.ai/adarshn-work/python-random-forests-assignment/v/10#C67)\n",
    "- [Correlation matrix plotting](https://stackoverflow.com/questions/29432629/plot-correlation-matrix-using-pandas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20943c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
