{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 6\n",
    "\n",
    "The goal of this homework is to create a tree-based regression model for prediction apartment prices (column `'price'`).\n",
    "\n",
    "In this homework we'll again use the New York City Airbnb Open Data dataset - the same one we used in homework 2 and 3.\n",
    "\n",
    "You can take it from [Kaggle](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv)\n",
    "or download from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv)\n",
    "if you don't want to sign up to Kaggle.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'neighbourhood_group', 'room_type', 'latitude', 'longitude',\n",
    "    'minimum_nights', 'number_of_reviews','reviews_per_month',\n",
    "    'calculated_host_listings_count', 'availability_365','price'\n",
    "]\n",
    "\n",
    "target = 'price'\n",
    "\n",
    "df = pd.read_csv('nyc.csv', usecols=columns)\n",
    "df.reviews_per_month = df.reviews_per_month.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the log tranform to `price`\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = np.log1p(df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['price']\n",
    "df.drop(columns= ['price'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target, test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `DictVectorizer` to turn train and validation into matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train), len(y_train))\n",
    "print(len(x_val), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = x_train.to_dict(orient= 'records')\n",
    "train_dv = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = x_val.to_dict(orient= 'records')\n",
    "val_dv = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the price variable. \n",
    "\n",
    "* Train a model with `max_depth=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "reg = DecisionTreeRegressor(max_depth= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `room_type`\n",
    "* `neighbourhood_group`\n",
    "* `number_of_reviews`\n",
    "* `reviews_per_month`\n",
    "\n",
    "> room_type=Entire home/apt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(train_dv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feature = np.argmax(reg.feature_importances_)\n",
    "\n",
    "dv.get_feature_names()[imp_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "print(export_text(reg, feature_names=dv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1`  (optional - to make training faster)\n",
    "\n",
    ">Validation RMSE: 0.211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state= 1, n_jobs= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(train_dv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(val_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(y_true= y_val, y_pred = y_pred, squared= False)\n",
    "print(f'Validation RMSE: {round(rmse, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.059\n",
    "* 0.259\n",
    "* 0.459\n",
    "* 0.659\n",
    "\n",
    "> Validation RMSE: 0.46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10\n",
    "* Set `random_state` to `1`\n",
    "* Evaluate the model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_params(**params):\n",
    "    \"\"\"\n",
    "    - Train a model with hyperparameter passed to function \n",
    "    - Predict  on validation set\n",
    "    - Evaluate MSE\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor(**params, random_state= 1).fit(train_dv, y_train)\n",
    "    pred = model.predict(val_dv)\n",
    "    val_rmse = mean_squared_error(y_val, pred,  squared=False)\n",
    "    return val_rmse\n",
    "\n",
    "def test_multiple_values(param_name, param_values):\n",
    "    \"\"\"\n",
    "    For given param_name and range of values, train a model individually through function test_params\n",
    "    and fetch-append validation RMSE\n",
    "    \"\"\"\n",
    "    val_errors = []\n",
    "    for value in param_values:\n",
    "        params = {param_name: value}\n",
    "        metric = test_params(**params)\n",
    "        val_errors.append(round(metric, 5))\n",
    "        print(f'Error evaluated for {param_name}:{value}')\n",
    "    return val_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile param values and rmse values together\n",
    "estimators_range = [i for i in range(10, 201, 10)]\n",
    "rmse_list = list(zip(estimators_range,(test_multiple_values('n_estimators', estimators_range))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse_list = [(10, 0.45985),\n",
    "#  (20, 0.44783),\n",
    "#  (30, 0.44512),\n",
    "#  (40, 0.44323),\n",
    "#  (50, 0.44223),\n",
    "#  (60, 0.44153),\n",
    "#  (70, 0.44087),\n",
    "#  (80, 0.44076),\n",
    "#  (90, 0.44024),\n",
    "#  (100, 0.43978),\n",
    "#  (110, 0.43933),\n",
    "#  (120, 0.43914),\n",
    "#  (130, 0.43926),\n",
    "#  (140, 0.43911),\n",
    "#  (150, 0.4391),\n",
    "#  (160, 0.43891),\n",
    "#  (170, 0.43887),\n",
    "#  (180, 0.43905),\n",
    "#  (190, 0.43895),\n",
    "#  (200, 0.43894)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, rmse = zip(*rmse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plt.plot(estimators_range, rmse)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('RMSE')\n",
    "plt.annotate('min RMSE point',(100, 0.193), xytext = (150, 0.1975), arrowprops=dict(arrowstyle=\"simple\"\\\n",
    "                        ,connectionstyle=\"arc3,rad=0.3\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "\n",
    "- 10\n",
    "- 50\n",
    "- 70\n",
    "- 120\n",
    "\n",
    "> 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values, try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "* Fix the random seed: `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scores = []\n",
    "\n",
    "# max_depth_range = [10, 15, 20, 25]\n",
    "\n",
    "# for depth in max_depth_range:\n",
    "#     print(f'Evaluating for max depth: {depth}')\n",
    "#     for num_estimators in estimators_range:\n",
    "#         rf = RandomForestRegressor(n_estimators=num_estimators,\n",
    "#                                     max_depth=depth,\n",
    "#                                     random_state=1)\n",
    "#         rf.fit(train_dv, y_train)\n",
    "#         y_pred = rf.predict(val_dv)\n",
    "#         rmse = mean_squared_error(y_val, y_pred, squared= True)\n",
    "#         print('.',sep=\"\")\n",
    "#         scores.append((depth, num_estimators, rmse))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['max_depth', 'n_estimators', 'rmse']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in max_depth_range:\n",
    "    df_subset = df_scores[df_scores.max_depth == d]\n",
    "    \n",
    "    plt.plot(df_subset.n_estimators, df_subset.rmse,\n",
    "             label=f'max_depth={d}')\n",
    "    plt.xlabel('n_estimators')\n",
    "    plt.ylabel('RMSE')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best `max_depth`:\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25\n",
    "\n",
    ">15\n",
    "\n",
    "Bonus question (not graded):\n",
    "\n",
    "Will the answer be different if we change the seed for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorith, it finds the best split. \n",
    "When doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the imporatant features \n",
    "for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the `feature_importances_` field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parametes:\n",
    "    * `n_estimators=10`,\n",
    "    * `max_depth=20`,\n",
    "    * `random_state=1`,\n",
    "    * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest5 = RandomForestRegressor(n_estimators=10, max_depth= 20, random_state= 1, n_jobs= -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest5.fit(train_dv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feature_q5 = np.argmax(forest5.feature_importances_)\n",
    "\n",
    "dv.get_feature_names()[imp_feature_q5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the most important feature? \n",
    "\n",
    "* `neighbourhood_group=Manhattan`\n",
    "* `room_type=Entire home/apt`\t\n",
    "* `longitude`\n",
    "* `latitude`\n",
    "\n",
    ">room_type=Entire home/apt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dv.get_feature_names()\n",
    "train_dmat = xgb.DMatrix(train_dv, y_train, feature_names= features)\n",
    "val_dmat = xgb.DMatrix(val_dv, y_val, feature_names= features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.01, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(train_dmat, 'train'), (val_dmat, 'validation')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "model = xgb.train(xgb_params, train_dmat, num_boost_round= 100,verbose_eval=5, evals= watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xgb_output(output):\n",
    "    results = []\n",
    "\n",
    "    for line in output.stdout.strip().split('\\n'):\n",
    "        it_line, train_line, val_line = line.split('\\t')\n",
    "\n",
    "        it = int(it_line.strip('[]'))\n",
    "        train = float(train_line.split(':')[1])\n",
    "        val = float(val_line.split(':')[1])\n",
    "\n",
    "        results.append((it, train, val))\n",
    "    \n",
    "    columns = ['num_iter', 'train_rmse', 'val_rmse']\n",
    "    df_results = pd.DataFrame(results, columns=columns)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta03 = parse_xgb_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eta03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta01 = parse_xgb_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta001 = parse_xgb_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now change `eta` first to `0.1` and then to `0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eta03['num_iter'], eta03['train_rmse'], color = 'black', label = 'eta 0.3')\n",
    "plt.plot(eta01['num_iter'], eta01['train_rmse'], color = 'blue', label = 'eta 0.1')\n",
    "plt.plot(eta001['num_iter'], eta001['train_rmse'], color = 'red', label = 'eta 0.01')\n",
    "\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best eta?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* 0.01\n",
    "\n",
    "> 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "\n",
    "Submit your results here: https://forms.gle/wQgFkYE6CtdDed4w8\n",
    "\n",
    "It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "\n",
    "The deadline for submitting is 20 October 2021, 17:00 CET (Wednesday). After that, the form will be closed.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
